{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0907ec7",
   "metadata": {},
   "source": [
    "# LangChain 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a80ce4",
   "metadata": {},
   "source": [
    "## 1. LangChain이란?\n",
    "\n",
    " - LangChain은 LLM(거대 언어 모델)을 활용하여 실제 애플리케이션을 쉽고 강력하게 구축할 수 있도록 도와주는 프레임워크입니다. \n",
    " - 단순히 모델을 호출하는 것을 넘어, 데이터 연결, 에이전트 생성, 체인 구성 등 LLM 애플리케이션에 필요한 다양한 기능을 모듈화하여 제공합니다.\n",
    "### 핵심 정의\n",
    "- LLM 기반 애플리케이션의 전체 라이프사이클을 단순화\n",
    "- 개발부터 배포까지 종합적인 솔루션 제공\n",
    "- 다양한 LLM 제공업체와의 표준화된 인터페이스 구현\n",
    "\n",
    "### Runnable 인터페이스\n",
    "- **Runnable**은 LangChain의 핵심 **인터페이스**\n",
    "- 호출(invoke), 배치(batch), 스트리밍(stream) 등이 가능한 표준 인터페이스입니다\n",
    "- LangChain의 모든 주요 구성요소(LLM, 프롬프트, 출력 파서, 에이전트 등)는 Runnable 프로토콜을 구현합니다\n",
    "\n",
    "### LangChain이 해결하는 문제\n",
    "- LLM을 실제 애플리케이션에 통합하는 복잡성\n",
    "- 다양한 AI 모델과 서비스 간의 일관성 부족\n",
    "- 프로덕션 환경에서의 모니터링과 최적화의 어려움\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460f1409",
   "metadata": {},
   "source": [
    "### 기본 사용 예제"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd47ad1c",
   "metadata": {},
   "source": [
    "#### 1. API 키 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985030c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env 파일에서 환경변수 로드\n",
    "load_dotenv()\n",
    "\n",
    "# OpenAI API 환경변수 값 확인\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "print(f\"OPENAI_API_KEY가 설정되어 있나요?: {openai_api_key[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75235f99",
   "metadata": {},
   "source": [
    "#### 2. 채팅 모델 초기화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b722601",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.5)\n",
    "\n",
    "print(\"모델이 성공적으로 초기화되었습니다!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e54f4a",
   "metadata": {},
   "source": [
    "#### 3.LLM 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3bd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 메시지 전송\n",
    "response = llm.invoke(\"안녕하세요! LangChain에 대해 간단히 설명해주세요.\")\n",
    "\n",
    "print(\"AI 응답:\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3e6ca7",
   "metadata": {},
   "source": [
    "\n",
    "#### AIMessage\n",
    "- LangChain에서 LLM 호출 시 `AIMessage` 객체가 반환됩니다. \n",
    "- LangChain 프레임워크에서 AI 언어 모델이 생성한 메시지를 나타내는 데이터 구조(클래스)입니다.\n",
    "---\n",
    "#### 주요 구성 요소\n",
    "**1. content**  \n",
    "- 모델이 실제로 생성한 답변 텍스트\n",
    "\n",
    "**2. additional_kwargs**  \n",
    "- 부가 옵션 (예: 거부 여부 `refusal`)  \n",
    "\n",
    "**3. response_metadata**  \n",
    "- 모델 관련 상세 정보\n",
    "  - 사용된 모델 이름 (`model_name`)  \n",
    "  - 토큰 사용량 (`prompt_tokens`, `completion_tokens`, `total_tokens`)  \n",
    "  - 응답 종료 이유 (`finish_reason`)  \n",
    "  \n",
    "**4. usage_metadata**  \n",
    "- LangChain이 정리한 토큰 사용량 요약  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a2ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d6c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.additional_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117b6569",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.response_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe22cf3",
   "metadata": {},
   "source": [
    "## 2.LCEL (Langchain Chain Expression Language)\n",
    "### LCEL이란?\n",
    "- Langchain에서 프롬프트, 체인, LLM 호출 등 다양한 구성요소는 Runnable 인터페이스를 구현하여, 함수형태로 조합할 수 있음.\n",
    "- 파이프라인처럼 여러 단계를 연결하여 복잡한 워크플로우를 간결하게 체인형태로 구현할 수 있다.\n",
    "- 각 단계는 함수(또는 객체)로 표현되며, 입력과 출력을 연결 가능하다.\n",
    "- 예시: (프롬프트 → LLM → 후처리) 과정을 한 줄로 연결하여 작성 가능합니다\n",
    "- `chain = prompt | model | output`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6e0283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"{input}가 무엇인가요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b318e45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.invoke(\"Agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea5652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c556453",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Agent\"\n",
    "\n",
    "response = chain.invoke(input)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c1e34f",
   "metadata": {},
   "source": [
    "### 다른 LLM 제공업체 옵션\n",
    "\n",
    "LangChain은 다양한 LLM 제공업체를 지원합니다:\n",
    "\n",
    "```python\n",
    "# Anthropic 사용\n",
    "pip install -qU \"langchain-anthropic\"\n",
    "model = init_chat_model(\"gpt-4o\", model_provider=\"openai\")\n",
    "\n",
    "# google-gemini 사용  \n",
    "pip install -qU \"langchain-google-genai\n",
    "\n",
    "model = init_chat_model(\"claude-3-sonnet-20240229\", model_provider=\"anthropic\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d0ab26",
   "metadata": {},
   "source": [
    "### 공식 리소스\n",
    "- **공식 문서**: [python.langchain.com](https://python.langchain.com)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
