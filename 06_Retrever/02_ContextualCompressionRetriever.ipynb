{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Contextual Compression Retriever란?\n",
        "- 검색된 문서에서 쿼리와 관련된 정보만을 압축하여 추출하는 Retriever\n",
        "- 기본 Retriever가 검색한 문서를 Document Compressor가 압축하여 품질을 향상\n",
        "- 불필요한 정보를 제거하여 LLM에 전달되는 정보의 노이즈 개선\n",
        "\n",
        "**기존 RAG 문제점**\n",
        "1. **관련 없는 정보**: 청크에 쿼리와 무관한 정보가 포함되어 LLM을 혼란시킴\n",
        "2. **토큰 낭비**: 긴 문서가 프롬프트 공간을 차지하여 비용 증가\n",
        "3. **정확도 저하**: 불필요한 정보로 인한 응답 품질 저하\n",
        "\n",
        "**핵심 개념**\n",
        "- **Base Retriever**: 기본 문서 검색을 담당하는 Retriever (VectorStore 등)\n",
        "- **Document Compressor**: 검색된 문서를 압축/필터링하는 구성요소\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "실습할 문서 만들기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"../data/[AI.GOV_해외동향]_2025-1호.pdf\")\n",
        "\n",
        "document = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "recursive_splitter = RecursiveCharacterTextSplitter(\n",
        "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \"],  # 문단 → 줄 → 문장 → 단어 순\n",
        "    chunk_size=300,    \n",
        "    chunk_overlap=30\n",
        ")\n",
        "\n",
        "chunks = recursive_splitter.split_documents(document)\n",
        "\n",
        "print(f\"총 {len(chunks)}개 청크 생성\\n\")\n",
        "\n",
        "for i, chunk in enumerate(chunks, 1):\n",
        "    chunk_length = len(chunk.page_content)\n",
        "    print(f\"청크 {i} ({chunk_length}자):\")\n",
        "    print(f\"'{chunk.page_content}'\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "임베딩 객체 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-3-small\", \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "Vector Store 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# FAISS 벡터 스토어 생성\n",
        "vectorstore = FAISS.from_documents(\n",
        "    documents=chunks, \n",
        "    embedding=embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "기본 VectorStore Retriever 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 기본 VectorStore Retriever 생성\n",
        "base_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# 기본 검색 테스트\n",
        "question = \"각국의 인프라 투자 상황에 대해 알려주세요\"\n",
        "docs = base_retriever.invoke(question)\n",
        "\n",
        "print(f\"=== 기본 검색 결과 (총 {len(docs)}개) ===\")\n",
        "\n",
        "for i, doc in enumerate(docs):\n",
        "    print(f\"문서 {i+1}:\")\n",
        "    print(f\"내용: {doc.page_content}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### LLMChainExtractor를 사용한 Contextual Compression\n",
        "\n",
        "**LLMChainExtractor**\n",
        "- LLM을 이용하여 문서나 텍스트로부터 정보(예: 키워드, 요약, 질문 등)를 추출하는 유틸\n",
        "- LLM + Prompt + OutputParser를 묶어서, 텍스트에서 원하는 정보를 추출 할 수도 있음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)\n",
        "\n",
        "# LLMChainExtractor 생성\n",
        "# 문서에서 쿼리와 관련된 정보만을 추출\n",
        "compressor = LLMChainExtractor.from_llm(llm)\n",
        "\n",
        "# ContextualCompressionRetriever 생성\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=base_retriever\n",
        ")\n",
        "\n",
        "# 압축된 검색 결과\n",
        "compressed_docs = compression_retriever.invoke(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "print(f\"LLMChainExtractor 압축 결과 (총 {len(compressed_docs)}개)\")\n",
        "for i, doc in enumerate(compressed_docs):\n",
        "    print(i)\n",
        "    print(f\"내용: {doc.page_content}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
