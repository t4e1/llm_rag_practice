{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7366a6d1",
   "metadata": {},
   "source": [
    "## RAG란?\n",
    "- 자연어 처리(NLP) 분야의 혁신적인 기술로, 기존 모델의 한계를 넘어서 정보 검색과 생성을 통합하는 방법론\n",
    "- 풍부한 정보를 담고 있는 대규모 문서 데이터베이스에서 관련정보를 검색하고, \n",
    "- 이를 통해 언어 모델이 더 정확하고 상세한 답변을 생성 할 수 있습니다.\n",
    "\n",
    "### 핵심 개념\n",
    "- **검색(Retrieval)**: 질문과 관련된 문서나 정보를 벡터 유사도 기반으로 찾기\n",
    "- **증강(Augmented)**: 찾은 정보를 언어 모델의 컨텍스트에 추가\n",
    "- **생성(Generation)**: 증강된 정보를 바탕으로 더 정확하고 신뢰할 수 있는 답변 생성\n",
    "\n",
    "\n",
    "### RAG의 장점\n",
    "1. 최신 정보 반영 가능 (지식 갱신이 간편)\n",
    "2. 출처 기반 응답 제공\n",
    "3. 도메인 특화 응답 가능\n",
    "\n",
    "### RAG의 기본구조\n",
    "\n",
    "![RAG.png](./images/RAG.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281ef186",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**RAG-FLOW**\n",
    "![RAG_Flow.png](./images/RAG_Flow.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c800d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## PDF를 문서로 사용해서 RAG 시스템 구축하기\n",
    "- 다음 실습 예시는 기본적인 RAG 구조를 구현합니다.\n",
    "- 추후, 개발을 진행할때는 각각의 구현 상황에 맞는 모듈로 바꾸는 것 만으로도 여러분들만의 RAG 시스템을 구축 할 수 있습니다.\n",
    "\n",
    "- 예시  \n",
    "지금 예시에서는 PDF를 읽어와 문서를 저장하고 있지만, 제공되는 문서가 Text일 경우 Docuemnt Loader 모듈을 바꾸어 사용할 수 있습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60c58dd",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "**실습자료**\n",
    "- 제목 : AI.GOV 해외동향 2025-1호\n",
    "- 링크 : [한국지능사회정보진흥원](https://www.innovation.go.kr/ucms/bbs/B0000051/view.do?nttId=17774&menuNo=300145&pageIndex=)  \n",
    "- 출처 : NIA 한국지증정보원원\n",
    "\n",
    "*링크에서 파일을 다운로드 받은후 최상단 data 폴더에 위치시켜주세요*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6cb4a6",
   "metadata": {},
   "source": [
    "### Step 1 : 문서 로드(Document Load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d81f0311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=0.3.75 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (0.3.76)\n",
      "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2.32.5 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.10.1 (from langchain_community)\n",
      "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain_community) (0.4.27)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.3.3-cp311-cp311-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (0.3.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain<2.0.0,>=0.3.27->langchain_community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langchain-core<2.0.0,>=0.3.75->langchain_community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<2.0.0,>=0.3.75->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<2.0.0,>=0.3.27->langchain_community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from requests<3,>=2.32.5->langchain_community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from langsmith>=0.1.125->langchain_community) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain_community) (1.3.1)\n",
      "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 13.2 MB/s  0:00:00\n",
      "Downloading aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.6.4-cp311-cp311-win_amd64.whl (46 kB)\n",
      "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Downloading frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.3.3-cp311-cp311-win_amd64.whl (13.1 MB)\n",
      "   ---------------------------------------- 0.0/13.1 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 4.2/13.1 MB 19.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 9.2/13.1 MB 21.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.1/13.1 MB 21.1 MB/s  0:00:00\n",
      "Downloading propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain_community\n",
      "\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -------- -------------------------------  3/15 [multidict]\n",
      "   ---------- -----------------------------  4/15 [marshmallow]\n",
      "   ------------- --------------------------  5/15 [httpx-sse]\n",
      "   --------------------- ------------------  8/15 [yarl]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-settings]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-settings]\n",
      "   -------------------------------- ------- 12/15 [dataclasses-json]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ---------------------------------------- 15/15 [langchain_community]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain_community-0.3.29 marshmallow-3.26.1 multidict-6.6.4 mypy-extensions-1.1.0 numpy-2.3.3 propcache-0.3.2 pydantic-settings-2.10.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# langchain_community : Langchain 핵심 기능 외에 커뮤니티가 기여하고 유지보수하는 외부 서비스 패키지지\n",
    "%pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7fdb722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-6.0.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Downloading pypdf-6.0.0-py3-none-any.whl (310 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-6.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# python으로 PDF문서를 빠르고 쉽게 열고 내용을 추출하거나 파일을 수정 및 이미지 저장을 해주는 라이브러리\n",
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af979fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DoucmentLoader\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"../data/[AI.GOV_해외동향]_2025-1호.pdf\")\n",
    "\n",
    "docs = loader.load()\n",
    "\n",
    "print(f\"1번째 문서 내용 : {docs[5].page_content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38daab9",
   "metadata": {},
   "source": [
    "메타데이터 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787e18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb2fcfb",
   "metadata": {},
   "source": [
    "### Step 2 : 문서 분할하기 (Text Splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6acbe",
   "metadata": {},
   "source": [
    "### Character Text Splitter\n",
    "`CharacterTextSplitter`는 가장 기본적인 텍스트 분할 도구입니다.  \n",
    "특정 문자(separator)를 기준으로 텍스트를 나누어 작은 청크(chunk)로 만들어줍니다.\n",
    "\n",
    "**chunk란?**  \n",
    "문장을 분석/처리 하기 쉽게 텍스트를 작은 단위로 나눈 조각을 의미합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63719da",
   "metadata": {},
   "source": [
    "기본 사용법\n",
    "\n",
    "CharacterTextSplitter의 기본 구조는 다음과 같습니다:\n",
    "\n",
    "**주요 매개변수**\n",
    "- `separator`: 텍스트를 나눌 기준 문자 (기본값: `\"\\n\\n\"`)\n",
    "- `chunk_size`: 각 청크의 최대 문자 수\n",
    "- `chunk_overlap`: 인접한 청크 간 겹치는 문자 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e431b7",
   "metadata": {},
   "source": [
    "Chunk Overlap이해하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39a2eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chunck Overlap 이해하기\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "sample_text = \"이것은 오버랩 개념을 설명하기 위한 예시 문장입니다. 문맥이 끊어지지 않도록 도와줍니다.\"\n",
    "\n",
    "# 1. Overlap 없이 분할하는 Splitter 생성\n",
    "no_overlap_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",         # 띄어쓰기 단위로 분할\n",
    "    chunk_size=25,         # Chunk 최대 크기를 25자로 설정\n",
    "    chunk_overlap=10,       # 겹치는 부분 없음\n",
    ")\n",
    "\n",
    "# 2. 텍스트 분할 실행\n",
    "chunks = no_overlap_splitter.split_text(sample_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c59855",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Overlap이 없을 때 (chunk_overlap=0) ---\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: \\\"{chunk}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a7532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Overlap이 있을 때 (chunk_overlap=10) ---\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1}: \\\"{chunk}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d5c75",
   "metadata": {},
   "source": [
    "띄워쓰기가 없는 아주 긴 단어라면?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5075eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter # 바꿔써보기기\n",
    "\n",
    "long_word_text = \"이것은테스트입니다슈퍼울트라하이퍼메가캡숑단어\"\n",
    "\n",
    "# chunk_size를 10으로 아주 작게 설정\n",
    "long_word_splitter = CharacterTextSplitter(\n",
    "    separator=\" \",         # 띄어쓰기 단위로 분할\n",
    "    chunk_size=5,         # Chunk 최대 크기를 25자로 설정\n",
    "    chunk_overlap=0,       # 겹치는 부분 없음\n",
    ")\n",
    "\n",
    "chunks = long_word_splitter.split_text(long_word_text)\n",
    "\n",
    "print(f\"--- chunk_size=10 설정 결과 ---\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i+1} (길이: {len(chunk)}): \\\"{chunk}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1e2e35",
   "metadata": {},
   "source": [
    "다시 RAG 구성으로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab118584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. TextSplitter\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# 기본 설정으로 텍스트 분할기 생성\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=200,     # 각 청크 최대 200자\n",
    "    chunk_overlap=20   # 20자씩 겹침\n",
    ")\n",
    "\n",
    "split_documents = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"분할된 청크의수: {len(split_documents)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322654f",
   "metadata": {},
   "source": [
    "분할결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de342fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(split_documents[4].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a70814",
   "metadata": {},
   "source": [
    "### Step 3 : 임베딩 준비하기 (Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4605b7d",
   "metadata": {},
   "source": [
    "#### Embedding이란?\n",
    "**텍스트 → 수치 벡터(vector)** 로 변환하는 작업  \n",
    "즉, 사람의 언어를 컴퓨터가 이해할 수 있는 형식으로 바꾸는 것.\n",
    "\n",
    "`RAG`에서 관련있는 문서를 검색 해 올 수 있어야 하기 때문에, 문서를 벡터화 시켜, 의미가 비슷한 문서를 찾을 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfdd2e",
   "metadata": {},
   "source": [
    "#### OpenAIEmbeddings\n",
    "- OpenAIEmbeddings는 LangChain에서 OpenAI의 강력한 임베딩 모델을 사용하기 위한 도구입니다.  \n",
    "\n",
    "\n",
    "**모델별 비교표**\n",
    "\n",
    "| 모델명 | 비용 (1백만 토큰 당) | 기본 벡터 차원 | 특징 및 장단점 |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **`text-embedding-3-small`** | **$0.02** | 1536 | **(추천)** **가성비가 가장 뛰어난 최신 모델.** `ada-002`보다 훨씬 저렴하지만 성능(특히 다국어)은 더 우수함. 대부분의 경우에 추천됨. |\n",
    "| **`text-embedding-3-large`** | $0.13 | 3072 | **최고 성능 모델.** 가장 높은 정확도를 제공하며, 미묘하고 복잡한 의미를 파악하는 데 가장 강력함. 비용과 벡터 저장 공간이 더 필요함. |\n",
    "| `text-embedding-ada-002` | $0.10 | 1536 | **(구세대 모델)** 과거에 가장 널리 쓰였던 모델. 특별한 이유가 없다면 이제는 `3-small` 모델 사용이 모든 면에서 유리함. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f90d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Embedding\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# 1. OpenAI 임베딩 모델 초기화 (ChatGPT-4o-mini와 호환)\n",
    "embeddings = OpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-small\",  # OpenAI의 최신 임베딩 모델\n",
    "    # API 키는 환경변수 OPENAI_API_KEY에서 자동으로 읽어옵니다\n",
    ")\n",
    "\n",
    "print(f\"모델명: {embeddings.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e77fe8",
   "metadata": {},
   "source": [
    "임베딩 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_vectors = embeddings.embed_documents(chunks)\n",
    "print(f\"--- 문서 임베딩 결과 ---\")\n",
    "print(f\"총 {len(document_vectors)}개의 Chunk가 벡터로 변환되었습니다.\")\n",
    "print(f\"각 벡터의 차원(길이): {len(document_vectors[0])}\")\n",
    "print(f\"첫 번째 Chunk의 벡터(일부): {document_vectors[0][:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6609e838",
   "metadata": {},
   "source": [
    "### Step 4 : Vector Store 생성 및 문서 임베딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56616ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.12.0-cp311-cp311-win_amd64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from faiss-cpu) (2.3.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\jtw57\\miniforge3\\envs\\helloworld\\lib\\site-packages (from faiss-cpu) (25.0)\n",
      "Downloading faiss_cpu-1.12.0-cp311-cp311-win_amd64.whl (18.2 MB)\n",
      "   ---------------------------------------- 0.0/18.2 MB ? eta -:--:--\n",
      "   ------------ --------------------------- 5.8/18.2 MB 29.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 10.7/18.2 MB 25.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 14.2/18.2 MB 22.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.1/18.2 MB 22.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 18.2/18.2 MB 21.6 MB/s  0:00:00\n",
      "Installing collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.12.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b035f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. VectorStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "db = FAISS.from_documents(documents=split_documents, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f669860c",
   "metadata": {},
   "source": [
    "검색해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412f993",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"프랑스 AI Action Summit 투자 유치액\"\n",
    "\n",
    "# 가장 유사한 문서를 찾음\n",
    "# k : 찾아올 갯수수\n",
    "docs = db.similarity_search(query, k=2)\n",
    "\n",
    "print(\"[가장 유사한 문서]\\n\" + docs[0].page_content)\n",
    "print(\"[그다음 유사한 문서]\\n\" + docs[1].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce0a26f",
   "metadata": {},
   "source": [
    "### Step 5 : Retriever 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1feaad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Retriever\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c61be1",
   "metadata": {},
   "source": [
    "### Step 6 : 프롬프트 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e3e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"당신은 질문에 답변하는 작업을 수행하는 어시스턴트입니다.\n",
    "다음에 제공된 문맥 정보를 바탕으로 질문에 답하세요.\n",
    "정답을 모를 경우, 모른다고만 말하세요.\n",
    "답변은 반드시 한국어로 작성하세요.\n",
    "\n",
    "#문맥:\n",
    "{context}\n",
    "\n",
    "#질문:\n",
    "{question}\n",
    "\n",
    "#답변:\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ceb39b2",
   "metadata": {},
   "source": [
    "### Step 7 : LLM 객체 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8d132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Model\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "# 문맥기반으로 대답을 해야하기 때문에 창의성 0으로 설정\n",
    "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a14b6d",
   "metadata": {},
   "source": [
    "### Step 8 : 체인 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9556c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Chain\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": retriever,\n",
    "        \"question\": RunnablePassthrough(), # 다음 체인으로 값을 그대로 넘김\n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f2e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. 테스트\n",
    "query = \"주요 해외 AI 에이전트 서비스 동향에 대해 알려줘\"\n",
    "response = chain.invoke(query)\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13dd10eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='프랑스 AI Action Summit에 대한 구체적인 투자 유치액은 제가 알고 있는 정보에는 포함되어 있지 않습니다. 이와 관련된 최신 정보는 공식 웹사이트나 관련 뉴스 기사를 통해 확인하시는 것이 좋습니다. AI 관련 행사에서는 종종 기업이나 스타트업이 투자 유치를 발표하기도 하므로, 관련 소식을 주의 깊게 살펴보시면 도움이 될 것입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 17, 'total_tokens': 103, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_8bda4d3a2c', 'id': 'chatcmpl-CEBjQlvlvre2wjlcuezysH1AyrixQ', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--ffca1b64-d5ef-436a-843e-0a075f91273a-0', usage_metadata={'input_tokens': 17, 'output_tokens': 86, 'total_tokens': 103, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "helloworld",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
