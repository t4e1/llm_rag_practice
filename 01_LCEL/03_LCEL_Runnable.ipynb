{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# LCEL Runnable 프로토콜"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 1. Runnable 프로토콜 소개\n",
        "\n",
        "### Runnable이란?\n",
        "- **Runnable**은 LangChain의 핵심 **인터페이스**\n",
        "- 호출(invoke), 배치(batch), 스트리밍(stream) 등이 가능한 표준 인터페이스입니다\n",
        "- LangChain의 모든 주요 구성요소(LLM, 프롬프트, 출력 파서, 리트리버 등)는 Runnable 프로토콜을 구현합니다"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 2. Runnable의 주요 메서드\n",
        "\n",
        "### 핵심 메서드들\n",
        "| 메서드 | 설명 | 사용 예시 |\n",
        "|--------|------|-----------|\n",
        "| `invoke()` | 단일 입력을 받아 출력 생성 | `runnable.invoke(input)` |\n",
        "| `batch()` | 여러 입력을 병렬로 처리 | `runnable.batch([input1, input2])` |\n",
        "| `stream()` | 출력을 스트리밍으로 생성 | `runnable.stream(input)` |\n",
        "| `astream_events()` | 이벤트 스트리밍 (고급) | `runnable.astream_events(input)` |\n",
        "\n",
        "### 입력/출력 타입 (컴포넌트별)\n",
        "| 컴포넌트 | 입력 타입 | 출력 타입 |\n",
        "|----------|-----------|-----------|\n",
        "| **Prompt** | 딕셔너리 객체 | PromptValue |\n",
        "| **ChatModel** | 문자열, 메시지 리스트, PromptValue | ChatMessage |\n",
        "| **LLM** | 문자열, 메시지 리스트, PromptValue | 문자열 |\n",
        "| **OutputParser** | LLM 또는 ChatModel의 출력 | 파서에 따라 다름 |\n",
        "| **Retriever** | 문자열 | Document 리스트 |\n",
        "| **Tool** | 문자열 또는 객체 | 도구에 따라 다름 |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**실습 준비 - 기본 설정**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### 기본 Runnable 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**invoke() 메서드 - 단일 입력 처리**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# 1. 프롬프트 템플릿 생성 (Runnable)\n",
        "prompt = PromptTemplate.from_template(\"다음 주제에 대해 한줄로 간단히 설명해주세요: {topic}\")\n",
        "\n",
        "# 2. 출력 파서 생성 (Runnable)\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# Langchain의 각 컴포넌트는 Runnable 프로토콜을 구현합니다\n",
        "# invoke 메서드를 사용하여 각 단계별로 실행\n",
        "input_data = {\"topic\": \"랭체인\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1단계: 프롬프트 생성\n",
        "formatted_prompt = prompt.invoke(input_data)\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2단계: LLM 실행\n",
        "llm_response = llm.invoke(formatted_prompt)\n",
        "print(llm_response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3단계: 출력 파싱\n",
        "final_output = output_parser.invoke(llm_response)\n",
        "print(final_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**체인 구성 - Pipe 연산자 (|) 사용**\n",
        "- LCEL의 핵심 기능: Pipe 연산자(`|`)를 사용한 체인 구성\n",
        "- 여러 Runnable을 연결하여 하나의 체인으로 만들 수 있습니다\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 1: Pipe 연산자 사용\n",
        "chain = prompt | llm | output_parser\n",
        "\n",
        "# 체인을 하나의 Runnable로 사용\n",
        "result = chain.invoke({\"topic\": \"머신러닝\"})\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RunnableSequence란?\n",
        "- 여러 Runnable을 순차적으로 실행하는 체인을 명시적으로 생성하는 클래스\n",
        "- Pipe 연산자(|)를 사용하는 것과 동일한 결과를 제공\n",
        "- 복잡한 체인 구성에서 유용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 방법 2: RunnableSequence 클래스 사용\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "\n",
        "sequence_chain = RunnableSequence(prompt, llm, output_parser)\n",
        "\n",
        "# 동일한 결과\n",
        "result2 = sequence_chain.invoke({\"topic\": \"딥러닝\"})\n",
        "print(\"RunnableSequence 결과:\")\n",
        "print(result2)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**batch() 메서드**\n",
        "- 여러 입력들 (목록)에 대해 체인을 호출 할 수 있습니다.\n",
        "- 병렬로 동작하지 않음."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# batch 메서드를 사용하여 여러 입력을 한 번에 처리\n",
        "topics = [\n",
        "    {\"topic\": \"블록체인\"},\n",
        "    {\"topic\": \"양자컴퓨팅\"},\n",
        "    {\"topic\": \"사물인터넷\"}\n",
        "]\n",
        "\n",
        "batch_results = chain.batch(topics)\n",
        "\n",
        "for i, (topic, result) in enumerate(zip(topics, batch_results)):\n",
        "    print(f\"\\n{i+1}. {topic['topic']}:\")\n",
        "    print(result)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "**stream() 메서드**\n",
        "- LLM의 출력을 실시간으로 스트리밍하여 받을 수 있는 메서드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "스트리밍 출력 (실시간으로 토큰이 생성됩니다):\n",
            "자연어처리(NLP)는 컴퓨터가 인간의 언어를 이해하고 해석하며 생성할 수 있도록 하는 인공지능의 한 분야입니다."
          ]
        }
      ],
      "source": [
        "# stream 메서드를 사용하여 실시간으로 출력 스트리밍\n",
        "print(\"스트리밍 출력 (실시간으로 토큰이 생성됩니다):\")\n",
        "\n",
        "for chunk in chain.stream({\"topic\": \"자연어처리\"}):\n",
        "    print(chunk, end=\"\", flush=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### RunnableParallel\n",
        "- 여러 개의 LangChain 실행 단위(Runnable)를 병렬로 동시에 실행하고  \n",
        " 그 결과를 하나의 딕셔너리(dictionary)로 묶어 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableParallel\n",
        "\n",
        "# 다양한 관점의 프롬프트 생성\n",
        "tech_prompt = PromptTemplate.from_template(\"기술적 관점에서 {topic}에 대해 한줄로 설명해주세요\")\n",
        "social_prompt = PromptTemplate.from_template(\"사회적 영향 관점에서 {topic}에 대해 한줄로 설명해주세요\")\n",
        "\n",
        "# 병렬 체인 구성\n",
        "parallel_chain = RunnableParallel(\n",
        "    technical=tech_prompt | llm | output_parser,\n",
        "    social=social_prompt | llm | output_parser\n",
        ")\n",
        "\n",
        "# 병렬 실행\n",
        "topic_input = {\"topic\": \"인공지능\"}\n",
        "results = parallel_chain.invoke(topic_input)\n",
        "\n",
        "print(\"1. 기술적 관점:\")\n",
        "print(results[\"technical\"])\n",
        "print(\"3. 사회적 영향 관점:\")\n",
        "print(results[\"social\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "### RunnableLambda \n",
        "- 커스텀 함수를 Runnable로 변환할 수 있다.\n",
        "- 일반적인 Python 함수를 LangChain 체인에 포함시킬 수 있도록 감싸는 래퍼(wrapper) 기능"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "# 1. 간단한 변환 함수들\n",
        "# 텍스트에 접두사 추가\n",
        "def add_prefix(text):\n",
        "    return f\"한줄설명: {text}\"\n",
        "\n",
        "# 함수들을 Runnable로 변환\n",
        "prefix_runnable = RunnableLambda(add_prefix)\n",
        "\n",
        "# 테스트\n",
        "sample_text = \"인공지능은 미래 기술의 핵심입니다\"\n",
        "\n",
        "print(\"원본 텍스트:\", sample_text)\n",
        "print(\"접두사 추가:\", prefix_runnable.invoke(sample_text))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Runnable 인터페이스로 만들어지기 때문에, chain으로 사용할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "enhanced_chain = (\n",
        "    prompt \n",
        "    | llm \n",
        "    | output_parser \n",
        "    | prefix_runnable  # 커스텀 함수를 체인에 추가\n",
        ")\n",
        "\n",
        "result = enhanced_chain.invoke({\"topic\": \"국방부\"})\n",
        "print(\"후처리가 포함된 체인 결과:\")\n",
        "print(result)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
